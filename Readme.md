# P2R-ZIP: Crowd Counting with Zero-Inflated Poisson + Point-to-Region Refinement

---

### ğŸ“˜ Descrizione del progetto

**P2R-ZIP** Ã¨ un framework di *crowd counting* che unisce due approcci complementari:

1. **ZIP (Zero-Inflated Poisson)** â€” Modello statistico per stimare la presenza e lâ€™intensitÃ  di persone a livello di blocchi.  
2. **P2R (Point-to-Region)** â€” Rete di raffinamento che genera una mappa di densitÃ  precisa a livello pixel.

Lâ€™obiettivo Ã¨ creare unâ€™architettura che prima individua le regioni dove ci sono persone (*coarse estimation*), e poi le raffina in modo dettagliato (*fine estimation*).  
Questo Ã¨ ottenuto tramite un flusso sequenziale:
Input â†’ Backbone CNN â†’ ZIP Head â†’ Mask Ï€ â†’ P2R Head â†’ Density Map

---

## ğŸ§© Architettura

- **Backbone condiviso:** es. VGG16-BN o ResNet50 pre-addestrato su ImageNet.
- **ZIP Head:** calcola per ogni blocco:
  - \( \pi \): probabilitÃ  che il blocco contenga persone,
  - \( \lambda \): valore atteso di conteggio (Poisson rate).
- **P2R Head:** prende le feature mascherate dalla ZIP Head e produce una mappa di densitÃ  raffinata.

---

## âš™ï¸ Struttura del repository

P2R_ZIP/
â”œâ”€ models/
â”‚ â”œâ”€ backbone.py # Backbone CNN
â”‚ â”œâ”€ zip_head.py # Testa ZIP (Ï€, Î»)
â”‚ â”œâ”€ p2r_head.py # Testa P2R
â”‚ â””â”€ p2r_zip_model.py # Architettura combinata ZIPâ†’P2R
â”‚
â”œâ”€ datasets/
â”‚ â”œâ”€ base_dataset.py # Classe base per caricamento immagini e punti
â”‚ â”œâ”€ jhu.py, shha.py,
â”‚ â”œâ”€ ucf_qnrf.py, nwpu.py # Dataset supportati
â”‚
â”œâ”€ losses/
â”‚ â”œâ”€ zip_nll.py # Loss Zero-Inflated Poisson NLL
â”‚ â””â”€ p2r_losses.py # Loss MSE + opzionale L1 sul conteggio
â”‚
â”œâ”€ train_utils.py # Resume, checkpoint, TensorBoard writer
â”‚
â”œâ”€ train_stage1_zip.py # Fase 1: pre-training ZIP
â”œâ”€ train_stage2_p2r.py # Fase 2: training P2R con ZIP congelato
â”œâ”€ train_stage3_joint.py # Fase 3: fine-tuning congiunto
â”‚
â”œâ”€ infer.py # Inferenza end-to-end ZIPâ†’P2R
â”œâ”€ config.yaml # Configurazione completa esperimento
â””â”€ README.md


---

## ğŸ§  PerchÃ© ci sono **tre file di training**

Il modello Ã¨ addestrato in **tre stadi progressivi** per garantire stabilitÃ  e specializzazione dei moduli:

### ğŸ©µ 1ï¸âƒ£ Stage 1 â€” Pre-training ZIP
- Allena **solo** il backbone e la ZIP Head.
- Loss: *Zero-Inflated Poisson NLL*.
- Obiettivo: imparare a identificare blocchi contenenti persone.
- Output: `exp/<run_name>_zip/best_model.pth`.

### ğŸ’™ 2ï¸âƒ£ Stage 2 â€” Training P2R
- Carica ZIP pre-addestrata e **la congela**.
- Allena **solo la P2R Head** sulle annotazioni puntuali.
- Loss: *MSE sulla mappa di densitÃ  + opzionale L1 sul conteggio*.
- Output: `exp/<run_name>_p2r/best_model.pth`.

### ğŸ’œ 3ï¸âƒ£ Stage 3 â€” Joint Fine-tuning
- Sblocca tutto il modello.
- Loss combinata:
  \[
  L_{total} = L_{ZIP} + \alpha L_{P2R}
  \]
- Ottimizza coerenza e precisione globale.
- Output: `exp/<run_name>_joint/best_model.pth`.

---

## âš–ï¸ Approfondimento: la **Loss combinata**

Durante il fine-tuning congiunto (Stage 3), la rete viene ottimizzata con una **loss ibrida** che bilancia due obiettivi:

\[
L_{total} = L_{ZIP} + \alpha \, L_{P2R}
\]

dove:

### ğŸ”¹ 1. \( L_{ZIP} \): Zero-Inflated Poisson Loss
Serve a modellare i **conteggi per blocco**.  
Ogni blocco ha due parametri:
- \( \pi \): probabilitÃ  che il blocco sia vuoto (nessuna persona),
- \( \lambda \): intensitÃ  media (Poisson rate) se il blocco Ã¨ occupato.

La loss NLL per il blocco \( i \) Ã¨:
\[
L_{ZIP} = - \log \left[ \pi_i \mathbf{1}_{\{c_i=0\}} + (1-\pi_i) e^{-\lambda_i} \frac{\lambda_i^{c_i}}{c_i!} \right]
\]

In sintesi:
- Se il blocco Ã¨ vuoto, la rete Ã¨ premiata se \( \pi_i \) Ã¨ alto.
- Se Ã¨ occupato, la rete Ã¨ premiata se \( \lambda_i \) stima correttamente il conteggio.

Questa formulazione permette di gestire dataset **sbilanciati**, in cui la maggior parte dei blocchi Ã¨ priva di persone.

---

### ğŸ”¹ 2. \( L_{P2R} \): Point-to-Region Loss
Serve a **raffinare la mappa di densitÃ ** a livello di pixel.

Viene calcolata come:
\[
L_{P2R} = \frac{1}{HW} \sum_{x,y} (D_{pred}(x,y) - D_{gt}(x,y))^2 + \beta \, \left| \sum D_{pred} - \sum D_{gt} \right|
\]

dove:
- \( D_{pred} \): mappa di densitÃ  predetta,
- \( D_{gt} \): mappa generata dai punti annotati con un kernel gaussiano (Ïƒ definito in `config.yaml`),
- \( \beta \): coefficiente del termine L1 sul conteggio totale (parametro `COUNT_L1_W`).

Il primo termine (MSE) forza la rete a replicare la forma della mappa di densitÃ ,  
il secondo (L1) mantiene il **conteggio totale coerente** con le annotazioni.

---

### ğŸ”¹ 3. Ruolo di **Î± (alpha)**

Il parametro `Î±` (`JOINT_ALPHA` nel file di configurazione) **bilancia lâ€™importanza** tra la parte ZIP e la parte P2R della loss totale:

- `Î± < 1` â†’ prioritÃ  al conteggio globale (ZIP prevale)  
  â†’ utile per dataset **sparsi** (es. NWPU-Crowd).  
- `Î± = 1` â†’ bilanciamento standard,  
  â†’ consigliato per dataset **equilibrati** (es. ShanghaiTechA).  
- `Î± > 1` â†’ prioritÃ  alla precisione locale (P2R prevale)  
  â†’ utile per dataset **densi** (es. JHU-CROWD, UCF-QNRF).

In pratica, **Î± controlla la scala di attenzione**:  
se la rete deve concentrarsi piÃ¹ sul â€œdoveâ€ (ZIP) o sul â€œquantoâ€ (P2R).

---

### ğŸ”¹ 4. Loss totale finale

Combinando tutto:

\[
L_{total} = L_{ZIP} + \alpha \left[ L_{P2R}^{MSE} + \beta L_{count} \right]
\]

dove:
- \( L_{ZIP} \) â†’ regola la struttura globale del crowd,  
- \( L_{P2R}^{MSE} \) â†’ regola la precisione locale,  
- \( L_{count} \) â†’ mantiene coerente il conteggio totale,  
- \( \alpha \) â†’ bilancia i due livelli (globale â†” locale).

---

### ğŸ’¡ Intuizione finale

> La loss combinata guida la rete in modo gerarchico:  
> prima **capisci dove** ci sono persone (ZIP), poi **affina quanto e dove esattamente** (P2R).  
>  
> Il parametro **Î±** regola lâ€™equilibrio tra queste due â€œintelligenzeâ€ complementari.

---

## ğŸ“¦ Dataset supportati

| Dataset | Split | Formato Ground Truth | Descrizione |
|----------|--------|----------------------|--------------|
| **JHU-CROWD++** | train/val | `.txt` (x y) | Scene urbane e affollate |
| **UCF-QNRF** | train/test | `.mat` (annPoints) | Immagini ad alta risoluzione |
| **ShanghaiTech Part A** | train/test | `.mat` | Scene indoor e outdoor |
| **NWPU-Crowd** | train/val | `.txt` (x y) | Dataset su larga scala |

---

## âš™ï¸ Configurazione (`config.yaml`)

```yaml
RUN_NAME: "jhu_p2rzip_v1"
DATASET: "jhu"
DATA:
  ROOT: "/mnt/localstorage/datasets/jhu_crowd_v2"
  ZIP_BLOCK_SIZE: 32
MODEL:
  BACKBONE: "vgg16_bn"
  GATE: "multiply"
OPTIM:
  EPOCHS: 300
  VAL_INTERVAL: 10
  RESUME_LAST: true
LOSS:
  JOINT_ALPHA: 1.0       # bilancia ZIP vs P2R
  P2R_SIGMA: 4.0         # Ïƒ per generare mappa densitÃ 
  COUNT_L1_W: 0.01       # peso Î² del conteggio
EXP:
  OUT_DIR: "exp"