# P2R-ZIP: Crowd Counting with Zero-Inflated Poisson + Point-to-Region Refinement

---

### üìò Descrizione del progetto

**P2R-ZIP** √® un framework di *crowd counting* che unisce due approcci complementari:

1. **ZIP (Zero-Inflated Poisson)** ‚Äî Modello statistico per stimare la presenza e l‚Äôintensit√† di persone a livello di blocchi.  
2. **P2R (Point-to-Region)** ‚Äî Rete di raffinamento che genera una mappa di densit√† precisa a livello pixel.

L‚Äôobiettivo √® creare un‚Äôarchitettura che prima individua le regioni dove ci sono persone (*coarse estimation*), e poi le raffina in modo dettagliato (*fine estimation*).  
Questo √® ottenuto tramite un flusso sequenziale:
Input ‚Üí Backbone CNN ‚Üí ZIP Head ‚Üí Mask œÄ ‚Üí P2R Head ‚Üí Density Map

---

## üß© Architettura

- **Backbone condiviso:** es. VGG16-BN o ResNet50 pre-addestrato su ImageNet.
- **ZIP Head:** calcola per ogni blocco:
  - pi: probabilit√† che il blocco contenga persone,
  - lambda: valore atteso di conteggio (Poisson rate).
- **P2R Head:** prende le feature mascherate dalla ZIP Head e produce una mappa di densit√† raffinata.

<p align="center">
  <img src="readme_image/architecture.png" alt="Architettura P2R-ZIP" width="650"/>
  <br>
  <em>Figura 1 ‚Äî Flusso sequenziale ZIP ‚Üí P2R (Zero-Inflated Poisson + Point-to-Region Refinement).</em>
</p>

---

## ‚öôÔ∏è Struttura del repository

```text
P2R_ZIP/
‚îú‚îÄ models/
‚îÇ  ‚îú‚îÄ backbone.py          # Backbone CNN
‚îÇ  ‚îú‚îÄ zip_head.py          # Testa ZIP (œÄ, Œª)
‚îÇ  ‚îú‚îÄ p2r_head.py          # Testa P2R
‚îÇ  ‚îî‚îÄ p2r_zip_model.py     # Architettura combinata ZIP‚ÜíP2R
‚îÇ
‚îú‚îÄ datasets/
‚îÇ  ‚îú‚îÄ base_dataset.py      # Classe base per caricamento immagini e punti
‚îÇ  ‚îú‚îÄ jhu.py, shha.py, ucf_qnrf.py, nwpu.py   # Dataset supportati
‚îÇ
‚îú‚îÄ losses/
‚îÇ  ‚îú‚îÄ zip_nll.py           # Loss Zero-Inflated Poisson NLL
‚îÇ  ‚îî‚îÄ p2r_losses.py        # Loss MSE + opzionale L1 sul conteggio
‚îÇ
‚îú‚îÄ train_utils.py          # Resume, checkpoint, TensorBoard writer
‚îÇ
‚îú‚îÄ train_stage1_zip.py     # Fase 1: pre-training ZIP
‚îú‚îÄ train_stage2_p2r.py     # Fase 2: training P2R con ZIP congelato
‚îú‚îÄ train_stage3_joint.py   # Fase 3: fine-tuning congiunto
‚îÇ
‚îú‚îÄ infer.py                # Inferenza end-to-end ZIP‚ÜíP2R
‚îú‚îÄ config.yaml             # Configurazione completa esperimento
‚îî‚îÄ README.md
```


## üß† Perch√© ci sono **tre file di training**

L‚Äôaddestramento del modello **P2R-ZIP** √® suddiviso in **tre stadi progressivi**, progettati per garantire stabilit√† numerica, separazione dei compiti e una convergenza pi√π robusta.  
Ogni fase affronta un sotto-problema specifico del crowd counting e contribuisce in modo complementare al risultato finale.

---

### ü©µ 1Ô∏è‚É£ Stage 1 ‚Äî Pre-training ZIP (Zero-Inflated Poisson)
**Obiettivo:**  
Addestrare la testa ZIP e il backbone a stimare correttamente la *distribuzione dei conteggi* nei blocchi dell‚Äôimmagine.

**Motivazione:**  
Le immagini di crowd counting contengono moltissime regioni vuote.  
Un modello non supervisionato su queste aree rischierebbe di imparare rumore.  
La ZIP Loss consente di modellare in modo statistico sia:
- la probabilit√† che un blocco contenga zero persone (pi),
- l‚Äôintensit√† media dei conteggi (lambda) nei blocchi non vuoti.

**Cosa impara:**  
- Il backbone estrattore di feature visive.  
- La ZIP Head, che distingue tra regioni *vuote* e *popolate*.  

**Output:**  
Un modello che sa *‚Äúdove guardare‚Äù* ‚Äî individua con buona precisione le zone dove √® probabile che ci sia crowd.

---

### üíô 2Ô∏è‚É£ Stage 2 ‚Äî Training P2R (Point-to-Region)
**Obiettivo:**  
Raffinare la mappa di densit√† a livello di pixel, partendo dalle aree identificate dal modulo ZIP.

**Motivazione:**  
La stima ZIP √® a grana grossa (per blocchi 16√ó16 o 32√ó32 pixel).  
Per ottenere conteggi precisi servono mappe *dense e continue* che riflettano le annotazioni puntuali.  

Durante questo stage:
- Il **backbone e la ZIP Head vengono congelati** (non aggiornati).  
- Si addestra **solo la P2R Head**, che apprende a proiettare le feature filtrate dalla maschera ZIP in una mappa di densit√† continua.  

**Loss utilizzata:**  
L_{P2R} = L_{MSE} + \beta L_{count}

dove il termine L1 opzionale garantisce coerenza nel conteggio totale.

**Cosa impara:**  
- La P2R Head apprende a stimare ‚Äúquanto e dove‚Äù ci sono persone all‚Äôinterno delle regioni attive previste da ZIP.  

**Output:**  
Un modello che sa *‚Äúquanto e dove esattamente‚Äù*, ma sempre vincolato dalle regioni ZIP.

---

### üíú 3Ô∏è‚É£ Stage 3 ‚Äî Joint Fine-tuning (Ottimizzazione congiunta)
**Obiettivo:**  
Integrare le due componenti (ZIP + P2R) in un addestramento unico, bilanciando le loro loss per ottenere una predizione coerente tra scala globale e scala locale.

**Motivazione:**  
Dopo le due fasi precedenti, ZIP e P2R lavorano bene separatamente ma non necessariamente in sinergia.  
Il fine-tuning congiunto consente di:
- adattare le feature condivise del backbone,
- migliorare la coerenza tra la probabilit√† di crowd (ZIP) e la densit√† generata (P2R),
- ottimizzare insieme la precisione e la consistenza globale.

**Loss combinata:**  
L_{total} = L_{ZIP} + \alpha L_{P2R}
dove:
- L_{ZIP} regola la stima dei blocchi e la struttura globale,  
- L_{P2R} regola la precisione locale pixel-wise,  
- \alpha  controlla il peso relativo dei due obiettivi.

**Interpretazione:**  
ZIP guida P2R fornendo un contesto spaziale affidabile;  
P2R affina la stima dentro le regioni attive di ZIP, migliorando la precisione del conteggio.

**Output:**  
Un modello end-to-end stabile, capace di combinare accuratezza locale e robustezza globale.

---

### üß© Riassunto visivo

| Stage | Moduli addestrati | Obiettivo | Output |
|-------|--------------------|------------|---------|
| **1Ô∏è‚É£ ZIP Pre-training** | Backbone + ZIP Head | Imparare dove c‚Äô√® crowd (regioni attive) | Maschera œÄ e Œª per blocchi |
| **2Ô∏è‚É£ P2R Training** | P2R Head | Raffinare la densit√† pixel-wise | Mappa densit√† coerente con i punti |
| **3Ô∏è‚É£ Joint Fine-tuning** | Tutto il modello | Integrare ZIP e P2R per coerenza globale | Predizione end-to-end stabile |

---

### üí° Intuizione finale

> La pipeline a tre stadi risolve il problema in modo gerarchico:  
> **ZIP** impara la *distribuzione globale del crowd*,  
> **P2R** ne affina la *rappresentazione locale*,  
> e lo **stage congiunto** armonizza le due scale, producendo mappe di densit√† accurate e consistenti.

---

## ‚öñÔ∏è Approfondimento: la **Loss combinata**

Durante il fine-tuning congiunto (Stage 3), la rete viene ottimizzata con una **loss ibrida** che bilancia due obiettivi:

L_{total} = L_{ZIP} + \alpha L_{P2R}

dove:

### üîπ 1. L_{ZIP}: Zero-Inflated Poisson Loss
Serve a modellare i **conteggi per blocco**.  
Ogni blocco ha due parametri:
- pi: probabilit√† che il blocco sia vuoto (nessuna persona),
- lambda: intensit√† media (Poisson rate) se il blocco √® occupato.

La loss NLL per il blocco i  √®:

L_ZIP = -log [ œÄ_i * I(c_i = 0) + (1 - œÄ_i) * exp(-Œª_i) * (Œª_i^c_i / c_i!) ]

In sintesi:
- Se il blocco √® vuoto, la rete √® premiata se pi_i √® alto.
- Se √® occupato, la rete √® premiata se lambda_i stima correttamente il conteggio.

Questa formulazione permette di gestire dataset **sbilanciati**, in cui la maggior parte dei blocchi √® priva di persone.

---

### üîπ 2. L_{P2R}: Point-to-Region Loss
Serve a **raffinare la mappa di densit√†** a livello di pixel.

Viene calcolata come:

L_P2R = (1 / (H * W)) * Œ£[(D_pred(x, y) - D_gt(x, y))¬≤] + Œ≤ * |Œ£D_pred - Œ£D_gt|

dove:
- D_{pred}: mappa di densit√† predetta,
- D_{gt}: mappa generata dai punti annotati con un kernel gaussiano (œÉ definito in `config.yaml`),
- beta: coefficiente del termine L1 sul conteggio totale (parametro `COUNT_L1_W`).

Il primo termine (MSE) forza la rete a replicare la forma della mappa di densit√†,  
il secondo (L1) mantiene il **conteggio totale coerente** con le annotazioni.

---

### üîπ 3. Ruolo di **Œ± (alpha)**

Il parametro `Œ±` (`JOINT_ALPHA` nel file di configurazione) **bilancia l‚Äôimportanza** tra la parte ZIP e la parte P2R della loss totale:

- `Œ± < 1` ‚Üí priorit√† al conteggio globale (ZIP prevale)  
  ‚Üí utile per dataset **sparsi** (es. NWPU-Crowd).  
- `Œ± = 1` ‚Üí bilanciamento standard,  
  ‚Üí consigliato per dataset **equilibrati** (es. ShanghaiTechA).  
- `Œ± > 1` ‚Üí priorit√† alla precisione locale (P2R prevale)  
  ‚Üí utile per dataset **densi** (es. JHU-CROWD, UCF-QNRF).

In pratica, **Œ± controlla la scala di attenzione**:  
se la rete deve concentrarsi pi√π sul ‚Äúdove‚Äù (ZIP) o sul ‚Äúquanto‚Äù (P2R).

---

### üîπ 4. Loss totale finale

Combinando tutto:

L_{total} = L_{ZIP} + \alpha \left[ L_{P2R}^{MSE} + \beta L_{count} \right]

dove:
- L_{ZIP} ‚Üí regola la struttura globale del crowd,  
- L_{P2R}^{MSE} ‚Üí regola la precisione locale,  
- L_{count} ‚Üí mantiene coerente il conteggio totale,  
- alpha ‚Üí bilancia i due livelli (globale ‚Üî locale).

---

### üí° Intuizione finale

> La loss combinata guida la rete in modo gerarchico:  
> prima **capisci dove** ci sono persone (ZIP), poi **affina quanto e dove esattamente** (P2R).  
>  
> Il parametro **Œ±** regola l‚Äôequilibrio tra queste due ‚Äúintelligenze‚Äù complementari.

---

## üì¶ Dataset supportati

| Dataset | Split | Formato Ground Truth | Descrizione |
|----------|--------|----------------------|--------------|
| **JHU-CROWD++** | train/val | `.txt` (x y) | Scene urbane e affollate |
| **UCF-QNRF** | train/test | `.mat` (annPoints) | Immagini ad alta risoluzione |
| **ShanghaiTech Part A** | train/test | `.mat` | Scene indoor e outdoor |
| **NWPU-Crowd** | train/val | `.txt` (x y) | Dataset su larga scala |

---

## ‚öôÔ∏è Configurazione (`config.yaml`)

```yaml
# P2R-ZIP: Crowd Counting with Zero-Inflated Poisson + Point-to-Region Refinement

---

### üìò Descrizione del progetto

**P2R-ZIP** √® un framework di *crowd counting* che unisce due approcci complementari:

1. **ZIP (Zero-Inflated Poisson)** ‚Äî Modello statistico per stimare la presenza e l‚Äôintensit√† di persone a livello di blocchi.  
2. **P2R (Point-to-Region)** ‚Äî Rete di raffinamento che genera una mappa di densit√† precisa a livello pixel.

L‚Äôobiettivo √® creare un‚Äôarchitettura che prima individua le regioni dove ci sono persone (*coarse estimation*), e poi le raffina in modo dettagliato (*fine estimation*).  
Questo √® ottenuto tramite un flusso sequenziale:
Input ‚Üí Backbone CNN ‚Üí ZIP Head ‚Üí Mask œÄ ‚Üí P2R Head ‚Üí Density Map

---

## üß© Architettura

- **Backbone condiviso:** es. VGG16-BN o ResNet50 pre-addestrato su ImageNet.
- **ZIP Head:** calcola per ogni blocco:
  - pi: probabilit√† che il blocco contenga persone,
  - lambda: valore atteso di conteggio (Poisson rate).
- **P2R Head:** prende le feature mascherate dalla ZIP Head e produce una mappa di densit√† raffinata.

<p align="center">
  <img src="readme_image/architecture.png" alt="Architettura P2R-ZIP" width="650"/>
  <br>
  <em>Figura 1 ‚Äî Flusso sequenziale ZIP ‚Üí P2R (Zero-Inflated Poisson + Point-to-Region Refinement).</em>
</p>

---

## ‚öôÔ∏è Struttura del repository

```text
P2R_ZIP/
‚îú‚îÄ models/
‚îÇ  ‚îú‚îÄ backbone.py          # Backbone CNN
‚îÇ  ‚îú‚îÄ zip_head.py          # Testa ZIP (œÄ, Œª)
‚îÇ  ‚îú‚îÄ p2r_head.py          # Testa P2R
‚îÇ  ‚îî‚îÄ p2r_zip_model.py     # Architettura combinata ZIP‚ÜíP2R
‚îÇ
‚îú‚îÄ datasets/
‚îÇ  ‚îú‚îÄ base_dataset.py      # Classe base per caricamento immagini e punti
‚îÇ  ‚îú‚îÄ jhu.py, shha.py, ucf_qnrf.py, nwpu.py   # Dataset supportati
‚îÇ
‚îú‚îÄ losses/
‚îÇ  ‚îú‚îÄ zip_nll.py           # Loss Zero-Inflated Poisson NLL
‚îÇ  ‚îî‚îÄ p2r_losses.py        # Loss MSE + opzionale L1 sul conteggio
‚îÇ
‚îú‚îÄ train_utils.py          # Resume, checkpoint, TensorBoard writer
‚îÇ
‚îú‚îÄ train_stage1_zip.py     # Fase 1: pre-training ZIP
‚îú‚îÄ train_stage2_p2r.py     # Fase 2: training P2R con ZIP congelato
‚îú‚îÄ train_stage3_joint.py   # Fase 3: fine-tuning congiunto
‚îÇ
‚îú‚îÄ infer.py                # Inferenza end-to-end ZIP‚ÜíP2R
‚îú‚îÄ config.yaml             # Configurazione completa esperimento
‚îî‚îÄ README.md
```


## üß† Perch√© ci sono **tre file di training**

L‚Äôaddestramento del modello **P2R-ZIP** √® suddiviso in **tre stadi progressivi**, progettati per garantire stabilit√† numerica, separazione dei compiti e una convergenza pi√π robusta.  
Ogni fase affronta un sotto-problema specifico del crowd counting e contribuisce in modo complementare al risultato finale.

---

### ü©µ 1Ô∏è‚É£ Stage 1 ‚Äî Pre-training ZIP (Zero-Inflated Poisson)
**Obiettivo:**  
Addestrare la testa ZIP e il backbone a stimare correttamente la *distribuzione dei conteggi* nei blocchi dell‚Äôimmagine.

**Motivazione:**  
Le immagini di crowd counting contengono moltissime regioni vuote.  
Un modello non supervisionato su queste aree rischierebbe di imparare rumore.  
La ZIP Loss consente di modellare in modo statistico sia:
- la probabilit√† che un blocco contenga zero persone (pi),
- l‚Äôintensit√† media dei conteggi (lambda) nei blocchi non vuoti.

**Cosa impara:**  
- Il backbone estrattore di feature visive.  
- La ZIP Head, che distingue tra regioni *vuote* e *popolate*.  

**Output:**  
Un modello che sa *‚Äúdove guardare‚Äù* ‚Äî individua con buona precisione le zone dove √® probabile che ci sia crowd.

---

### üíô 2Ô∏è‚É£ Stage 2 ‚Äî Training P2R (Point-to-Region)
**Obiettivo:**  
Raffinare la mappa di densit√† a livello di pixel, partendo dalle aree identificate dal modulo ZIP.

**Motivazione:**  
La stima ZIP √® a grana grossa (per blocchi 16√ó16 o 32√ó32 pixel).  
Per ottenere conteggi precisi servono mappe *dense e continue* che riflettano le annotazioni puntuali.  

Durante questo stage:
- Il **backbone e la ZIP Head vengono congelati** (non aggiornati).  
- Si addestra **solo la P2R Head**, che apprende a proiettare le feature filtrate dalla maschera ZIP in una mappa di densit√† continua.  

**Loss utilizzata:**  
L_{P2R} = L_{MSE} + \beta L_{count}

dove il termine L1 opzionale garantisce coerenza nel conteggio totale.

**Cosa impara:**  
- La P2R Head apprende a stimare ‚Äúquanto e dove‚Äù ci sono persone all‚Äôinterno delle regioni attive previste da ZIP.  

**Output:**  
Un modello che sa *‚Äúquanto e dove esattamente‚Äù*, ma sempre vincolato dalle regioni ZIP.

---

### üíú 3Ô∏è‚É£ Stage 3 ‚Äî Joint Fine-tuning (Ottimizzazione congiunta)
**Obiettivo:**  
Integrare le due componenti (ZIP + P2R) in un addestramento unico, bilanciando le loro loss per ottenere una predizione coerente tra scala globale e scala locale.

**Motivazione:**  
Dopo le due fasi precedenti, ZIP e P2R lavorano bene separatamente ma non necessariamente in sinergia.  
Il fine-tuning congiunto consente di:
- adattare le feature condivise del backbone,
- migliorare la coerenza tra la probabilit√† di crowd (ZIP) e la densit√† generata (P2R),
- ottimizzare insieme la precisione e la consistenza globale.

**Loss combinata:**  
L_{total} = L_{ZIP} + \alpha L_{P2R}
dove:
- L_{ZIP} regola la stima dei blocchi e la struttura globale,  
- L_{P2R} regola la precisione locale pixel-wise,  
- \alpha  controlla il peso relativo dei due obiettivi.

**Interpretazione:**  
ZIP guida P2R fornendo un contesto spaziale affidabile;  
P2R affina la stima dentro le regioni attive di ZIP, migliorando la precisione del conteggio.

**Output:**  
Un modello end-to-end stabile, capace di combinare accuratezza locale e robustezza globale.

---

### üß© Riassunto visivo

| Stage | Moduli addestrati | Obiettivo | Output |
|-------|--------------------|------------|---------|
| **1Ô∏è‚É£ ZIP Pre-training** | Backbone + ZIP Head | Imparare dove c‚Äô√® crowd (regioni attive) | Maschera œÄ e Œª per blocchi |
| **2Ô∏è‚É£ P2R Training** | P2R Head | Raffinare la densit√† pixel-wise | Mappa densit√† coerente con i punti |
| **3Ô∏è‚É£ Joint Fine-tuning** | Tutto il modello | Integrare ZIP e P2R per coerenza globale | Predizione end-to-end stabile |

---

### üí° Intuizione finale

> La pipeline a tre stadi risolve il problema in modo gerarchico:  
> **ZIP** impara la *distribuzione globale del crowd*,  
> **P2R** ne affina la *rappresentazione locale*,  
> e lo **stage congiunto** armonizza le due scale, producendo mappe di densit√† accurate e consistenti.

---

## ‚öñÔ∏è Approfondimento: la **Loss combinata**

Durante il fine-tuning congiunto (Stage 3), la rete viene ottimizzata con una **loss ibrida** che bilancia due obiettivi:

L_{total} = L_{ZIP} + \alpha L_{P2R}

dove:

### üîπ 1. L_{ZIP}: Zero-Inflated Poisson Loss
Serve a modellare i **conteggi per blocco**.  
Ogni blocco ha due parametri:
- pi: probabilit√† che il blocco sia vuoto (nessuna persona),
- lambda: intensit√† media (Poisson rate) se il blocco √® occupato.

La loss NLL per il blocco i  √®:

L_ZIP = -log [ œÄ_i * I(c_i = 0) + (1 - œÄ_i) * exp(-Œª_i) * (Œª_i^c_i / c_i!) ]

In sintesi:
- Se il blocco √® vuoto, la rete √® premiata se pi_i √® alto.
- Se √® occupato, la rete √® premiata se lambda_i stima correttamente il conteggio.

Questa formulazione permette di gestire dataset **sbilanciati**, in cui la maggior parte dei blocchi √® priva di persone.

---

### üîπ 2. L_{P2R}: Point-to-Region Loss
Serve a **raffinare la mappa di densit√†** a livello di pixel.

Viene calcolata come:

L_P2R = (1 / (H * W)) * Œ£[(D_pred(x, y) - D_gt(x, y))¬≤] + Œ≤ * |Œ£D_pred - Œ£D_gt|

dove:
- D_{pred}: mappa di densit√† predetta,
- D_{gt}: mappa generata dai punti annotati con un kernel gaussiano (œÉ definito in `config.yaml`),
- beta: coefficiente del termine L1 sul conteggio totale (parametro `COUNT_L1_W`).

Il primo termine (MSE) forza la rete a replicare la forma della mappa di densit√†,  
il secondo (L1) mantiene il **conteggio totale coerente** con le annotazioni.

---

### üîπ 3. Ruolo di **Œ± (alpha)**

Il parametro `Œ±` (`JOINT_ALPHA` nel file di configurazione) **bilancia l‚Äôimportanza** tra la parte ZIP e la parte P2R della loss totale:

- `Œ± < 1` ‚Üí priorit√† al conteggio globale (ZIP prevale)  
  ‚Üí utile per dataset **sparsi** (es. NWPU-Crowd).  
- `Œ± = 1` ‚Üí bilanciamento standard,  
  ‚Üí consigliato per dataset **equilibrati** (es. ShanghaiTechA).  
- `Œ± > 1` ‚Üí priorit√† alla precisione locale (P2R prevale)  
  ‚Üí utile per dataset **densi** (es. JHU-CROWD, UCF-QNRF).

In pratica, **Œ± controlla la scala di attenzione**:  
se la rete deve concentrarsi pi√π sul ‚Äúdove‚Äù (ZIP) o sul ‚Äúquanto‚Äù (P2R).

---

### üîπ 4. Loss totale finale

Combinando tutto:

L_{total} = L_{ZIP} + \alpha \left[ L_{P2R}^{MSE} + \beta L_{count} \right]

dove:
- L_{ZIP} ‚Üí regola la struttura globale del crowd,  
- L_{P2R}^{MSE} ‚Üí regola la precisione locale,  
- L_{count} ‚Üí mantiene coerente il conteggio totale,  
- alpha ‚Üí bilancia i due livelli (globale ‚Üî locale).

---

### üí° Intuizione finale

> La loss combinata guida la rete in modo gerarchico:  
> prima **capisci dove** ci sono persone (ZIP), poi **affina quanto e dove esattamente** (P2R).  
>  
> Il parametro **Œ±** regola l‚Äôequilibrio tra queste due ‚Äúintelligenze‚Äù complementari.

---

## üì¶ Dataset supportati

| Dataset | Split | Formato Ground Truth | Descrizione |
|----------|--------|----------------------|--------------|
| **JHU-CROWD++** | train/val | `.txt` (x y) | Scene urbane e affollate |
| **UCF-QNRF** | train/test | `.mat` (annPoints) | Immagini ad alta risoluzione |
| **ShanghaiTech Part A** | train/test | `.mat` | Scene indoor e outdoor |
| **NWPU-Crowd** | train/val | `.txt` (x y) | Dataset su larga scala |

---

## ‚öôÔ∏è Configurazione (`config.yaml`)

```yaml
RUN_NAME: "jhu_p2rzip_final"
SEED: 2024
DEVICE: "cuda"

# === DATASET ===
DATASET: "jhu"                        # jhu, ucf, shha, nwpu
DATA:
  ROOT: "/mnt/localstorage/datasets/jhu_crowd_v2"
  ZIP_BLOCK_SIZE: 16                  # stride del backbone VGG16-BN (1/16)
  IMG_EXTS: [".jpg", ".png"]
  NORM_MEAN: [0.485, 0.456, 0.406]
  NORM_STD:  [0.229, 0.224, 0.225]
  TRAIN_SPLIT: "train"
  VAL_SPLIT: "val"

# === MODELLO ===
MODEL:
  BACKBONE: "vgg16_bn"                # VGG16-BN -> stride 16
  ZIP_PI_THRESH: 0.5                  # soglia di attivazione ZIP
  GATE: "multiply"                    # 'multiply' o 'concat'
  UPSAMPLE_TO_INPUT: true

# === TRAINING ===
OPTIM:
  BATCH_SIZE: 4
  NUM_WORKERS: 4
  EPOCHS: 1300                        # come nel paper ZIP
  WARMUP_EPOCHS: 25                   # warm-up lineare (1e-5 ‚Üí 1e-4)
  LR: 1.0e-4
  LR_BACKBONE: 1.0e-5                 # come nel paper P2R
  WEIGHT_DECAY: 1.0e-4
  SCHEDULER: "cosine"                 # Cosine Annealing Restart (T‚ÇÄ=5, Tmult=2)
  VAL_INTERVAL: 10                    # validazione ogni 10 epoche
  RESUME_LAST: true                   # resume automatico
  SAVE_BEST: true

# === LOSS ===
LOSS:
  JOINT_ALPHA: 1.0                    # peso loss P2R nella fase joint
  P2R_SIGMA: 4.0                      # sigma per generare mappa densit√†
  COUNT_L1_W: 0.01                    # peso termine L1 sul conteggio totale

# === ESPERIMENTI ===
EXP:
  OUT_DIR: "exp"
  SAVE_BEST: true