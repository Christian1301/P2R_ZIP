# =================================================================
# CONFIGURAZIONE P2R-ZIP - VERSIONE CORRETTA v3
# =================================================================
# Correzioni rispetto a v2:
# 1. SCALE_WEIGHT drasticamente ridotto (0.10 → 0.02)
# 2. LOG_SCALE_CLAMP più stretto ([-3,2] → [-1.5,1.0])
# 3. MIN_RADIUS aumentato per stabilità BCE
# 4. Calibrazione più aggressiva
# 5. POS_WEIGHT P2R ridotto

RUN_NAME: "shha_target60_v3"
SEED: 2025
DEVICE: "cuda"

# === DATASET ===
DATASET: "shha"
DATA:
  ROOT: "/mnt/localstorage/cromano/Datasets/ShanghaiTech/part_A"
  ZIP_BLOCK_SIZE: 16
  P2R_DOWNSAMPLE: 8
  IMG_EXTS: [".jpg", ".png"]
  NORM_MEAN: [0.485, 0.456, 0.406]
  NORM_STD:  [0.229, 0.224, 0.225]
  TRAIN_SPLIT: "train_data"
  VAL_SPLIT: "val_data"
  CROP_SIZE: 384
  CROP_SCALE: [0.7, 1.0]

# === MODELLO ===
MODEL:
  BACKBONE: "vgg16_bn"
  ZIP_PI_THRESH: 0.5          
  GATE: "multiply"
  UPSAMPLE_TO_INPUT: false

# === ZIP HEAD CONFIGURATION ===
ZIP_HEAD:
  LAMBDA_SCALE: 1.2
  LAMBDA_MAX: 8.0
  USE_SOFTPLUS: true
  LAMBDA_NOISE_STD: 0.0

# -----------------------------------------------------------------
# STAGE 1: ZIP TRAINING (invariato)
# -----------------------------------------------------------------
OPTIM_ZIP:
  BATCH_SIZE: 6
  NUM_WORKERS: 4
  EPOCHS: 2000
  WEIGHT_DECAY: 3.0e-5
  SCHEDULER: "cosine"
  VAL_INTERVAL: 5
  RESUME_LAST: true
  SAVE_BEST: true
  BASE_LR: 8.0e-5
  LR_BACKBONE: 4.0e-5
  WARMUP_EPOCHS: 100
  EARLY_STOPPING_PATIENCE: 500
  EARLY_STOPPING_DELTA: 0.001

ZIP_LOSS:
  WEIGHT_CE: 1.5
  WEIGHT_NLL: 1.0
  WEIGHT_COUNT: 0.8
  WEIGHT_ALIGN: 0.4
  POS_WEIGHT_BCE: 5.0

ZIP_REG:
  PI_TARGET: 0.15
  PI_WEIGHT: 5.0e-4
  LAMBDA_TARGET: 5.0
  LAMBDA_WEIGHT: 1.0e-4

# -----------------------------------------------------------------
# STAGE 2: P2R TRAINING - CORREZIONI CRITICHE
# -----------------------------------------------------------------
OPTIM_P2R:
  BATCH_SIZE: 8                  # Ridotto da 10 per stabilità
  NUM_WORKERS: 4
  EPOCHS: 2000               
  LR: 8.0e-5                     # Ridotto da 1.2e-4
  LR_BACKBONE: 0.0               # CONGELATO completamente in Stage 2
  WEIGHT_DECAY: 1.0e-4
  SCHEDULER: "cosine"
  VAL_INTERVAL: 5            
  RESUME_LAST: true
  SAVE_BEST: true
  EARLY_STOPPING_PATIENCE: 500   
  EARLY_STOPPING_DELTA: 0.5      

P2R_LOSS:
  # CORREZIONE CRITICA 1: Scale weight molto ridotto
  # Era 0.10, causava scale_penalty >> BCE loss
  SCALE_WEIGHT: 0.02
  
  # CORREZIONE 2: POS_WEIGHT ridotto per bilanciare meglio
  POS_WEIGHT: 3.0                # Era 6.0
  
  CHUNK_SIZE: 2048
  
  # CORREZIONE 3: MIN_RADIUS aumentato per stabilità
  MIN_RADIUS: 8.0                # Era 4.0
  MAX_RADIUS: 50.0
  
  # CORREZIONE 4: Log scale più conservativo
  LOG_SCALE_INIT: -0.5           # Era -0.8
  LOG_SCALE_LR_FACTOR: 0.05      # Era 0.10 - impara più lentamente
  
  # CORREZIONE 5: Clamp più stretto
  LOG_SCALE_CLAMP: [-1.5, 1.0]   # Era [-3.0, 2.0]
  
  # CORREZIONE 6: Calibrazione più aggressiva
  LOG_SCALE_CALIBRATION_MAX_DELTA: 2.0  # Era 1.0
  CALIBRATE_BATCHES: 15                  # Era 8

# -----------------------------------------------------------------
# STAGE 3: JOINT TRAINING
# -----------------------------------------------------------------
OPTIM_JOINT:
  BATCH_SIZE: 4
  NUM_WORKERS: 4
  EPOCHS: 400
  
  LR_BACKBONE: 0.0               # CONGELATO in Stage 3
  LR_HEADS: 1.5e-5               # Ridotto da 2e-5
  
  WEIGHT_DECAY: 1.0e-4
  SCHEDULER: "cosine"
  SCHEDULER_STEP: "epoch"     
  WARMUP_EPOCHS: 50
  LR_MIN_FACTOR: 0.01         
  
  VAL_INTERVAL: 3
  EARLY_STOPPING_PATIENCE: 200
  EARLY_STOPPING_DELTA: 0.3
  
  LOAD_STAGE3_BEST: false     
  RESUME_LAST: true          
  SAVE_BEST: true             

JOINT_LOSS:
  ALPHA: 0.3                     # Ridotto da 0.5
  COUNT_L1_W: 2.0                # Aumentato da 1.5
  ZIP_SCALE: 0.2                 # Ridotto da 0.3
  ADAPTIVE_BALANCING: false   

# -----------------------------------------------------------------
# STAGE 4: RECOVERY
# -----------------------------------------------------------------
OPTIM_STAGE4:
  BATCH_SIZE: 4               
  NUM_WORKERS: 4              
  EPOCHS: 200
  
  LR_BACKBONE: 0.0
  LR_HEADS: 8.0e-6               # Molto basso
  
  WEIGHT_DECAY: 1.0e-4        
  SCHEDULER: "cosine"         
  SCHEDULER_STEP: "epoch"     
  WARMUP_EPOCHS: 10            
  VAL_INTERVAL: 2             
  EARLY_STOPPING_PATIENCE: 200

STAGE4_LOSS:
  ALPHA: 0.2
  ZIP_SCALE: 0.1
  COUNT_L1_W: 3.0                # Molto alto - focus su conteggio

# === BIN CONFIGURATION ===
BINS_CONFIG:
  shha:
    bins: [[0, 0], [1, 3], [4, 6], [7, 10], [11, 15], [16, 22], [23, 32], [33, 9999]]
    bin_centers: [0.0, 2.0, 5.0, 8.5, 13.0, 19.0, 27.5, 45.0]
  shhb:
    bins: [[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9999]]
    bin_centers: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 10.16]
  qnrf:
    bins: [[0,0],[1,1],[2,2],[3,3],[4,4],[5,5],[6,6],[7,7],[8,8],[9,9],[10,10],[11,12],[13,14],[15,16],[17,18],[19,20],[21,23],[24,26],[27,29],[30,33],[34,9999]]
    bin_centers: [0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.43,13.43,15.44,17.44,19.43,21.83,24.85,27.87,31.24,38.86]
  nwpu:
    bins: [[0,0],[1,1],[2,2],[3,3],[4,4],[5,5],[6,6],[7,7],[8,8],[9,9],[10,10],[11,12],[13,14],[15,16],[17,18],[19,20],[21,23],[24,26],[27,29],[30,33],[34,9999]]
    bin_centers: [0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.43,13.43,15.44,17.44,19.43,21.83,24.85,27.87,31.24,38.86]

EXP:
  OUT_DIR: "exp"
  SAVE_BEST: true
  SAVE_WORST_CASES: true